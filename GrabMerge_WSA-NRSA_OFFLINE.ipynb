{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "OFFLINE VERSION: Read in data from harddrive"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#OFFLINE VERSION\n",
      "\n",
      "#ipython --pylab\n",
      "import pandas\n",
      "from pandas import read_csv\n",
      "from urllib import urlopen\n",
      "import numpy as np\n",
      "from pandas import concat\n",
      "from pandas import merge\n",
      "\n",
      "#read in nrsa site info\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/NRSA_Data/NRSA0809_FinalDataFiles/NRSA0809_Data_SiteInformation_130411.csv'))\n",
      "nrsa_siteinfo = pandas.DataFrame(tmp,columns=['SITE_ID','MASTER_SITEID','UID','EPA_REG','FW_ECO3','FW_ECO9','GREAT_RIVER','HUC8','LMR_SITE','LOC_NAME',\n",
      "'MISS_SUB','NHDWAT_AREA_SQKM','STATE','STRAHLERORDER','VISIT_NO','WGTNRSA09','XLAT_DD','XLON_DD','YEAR'])\n",
      "\n",
      "#read in nrsa water chemistry\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/NRSA_Data/NRSA0809_FinalDataFiles/NRSA0809_Data_WaterChemistry_130322.csv'))\n",
      "nrsa_waterchem = pandas.DataFrame(tmp,columns=['SITE_ID','UID','YEAR','ANC','CA','CL','COND','DOC','K','MG','NTL',\n",
      "'PTL','SO4','SODIUM','TSS','TURB','VISIT_NO'])\n",
      "\n",
      "#read in water chemistry condition ratings (NOT FOUND IN WSA, SO NOT READ IN AT THIS POINT)\n",
      "#tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/NRSA_Data/NRSA0809_FinalDataFiles/NRSA0809_Data_WaterChemistry_Condition_130322.csv'))\n",
      "#nrsa_waterchem_cond = pandas.DataFrame(tmp,columns=['SITE_ID','UID','YEAR','VISIT_NO','ANC','COND','DOC','NTL','PTL','PTL_COND',\n",
      "#'SAL_COND'])\n",
      "\n",
      "\n",
      "#read in enterococci condition ratings\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/NRSA_Data/NRSA0809_FinalDataFiles/NRSA0809_Data_Enterococci_Condition_130322.csv'))\n",
      "nrsa_enterococci = pandas.DataFrame(tmp,columns=['SITE_ID','UID','YEAR','VISIT_NO','NRSA09','WSA','UrbanCat','WgtWSAeast','WgtEMAPwst','WgtNRSA09',\n",
      "                                                 'MAJ_BAS_NM','FED_OWN','FSEASTWEST','ENT_NEEAR_PCR_CCE_100ML','siteID05'])\n",
      "\n",
      "#read in nrsa benthic condition data\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/NRSA_Data/NRSA0809_FinalDataFiles/NRSA0809_Data_Benthics_Condition_130322.csv'))\n",
      "nrsa_benthic_cond = pandas.DataFrame(tmp,columns=['DIVS_PT','FEED_PT','HABT_PT','HPRIME','MMI_BENT_CPL','MMI_BENT_NAP',\n",
      "                                                  'MMI_BENT_NPL','MMI_BENT_SAP','MMI_BENT_SPL','MMI_BENT_TPL','MMI_BENT_UMW','MMI_BENT_WMT','MMI_BENT_XER',\n",
      "                                                  'NTAX_PT','SITE_ID','TOLR_PT','UID','VISIT_NO'])\n",
      "\n",
      "#read in nrsa fish condition data\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/NRSA_Data/NRSA0809_FinalDataFiles/NRSA0809_Data_Fish_Condition_130322.csv'))\n",
      "nrsa_fish_cond = pandas.DataFrame(tmp,columns=['SITE_ID','UID','VISIT_NO','FISH_MMI_COND','MMI_FISH_EHIGH','MMI_FISH_PLNLOW','MMI_FISH_WMTNS'])\n",
      "\n",
      "#read in nrsa periphyton condition data\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/NRSA_Data/NRSA0809_FinalDataFiles/NRSA0809_Data_Periphyton_Condition_130322.csv'))\n",
      "nrsa_peri_cond = pandas.DataFrame(tmp,columns=['SITE_ID','UID','VISIT_NO','MMI_PERI_EHIGH','MMI_PERI_PLNLOW','MMI_PERI_WMTNS','PERI_MMI_COND'])\n",
      "\n",
      "\n",
      "#read in physical habitat condition data\n",
      "#DOESN'T EXIST IN WSA, NOT READ IN HERE\n",
      "#tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/NRSA_Data/NRSA0809_FinalDataFiles/NRSA0809_Data_PhysicalHabitat_Condition_130322.csv'))\n",
      "#nrsa_hab_cond = pandas.DataFrame(tmp,columns=['SITE_ID','UID','VISIT_NO','YEAR','REACHLEN','W1_HAG','W1_HALL','W1_HNOAG','W1H_WALL','W1H_PIPE',\n",
      "#                                                  'XWIDTH','XFC_ALL','XWD_RAT','XCDENBK','XG'])\n",
      "\n",
      "#read in additional physical habitat condition data\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/NRSA_Data/NRSA0809_FinalDataFiles/NRSA0809_Data_PhysicalHabitat_Med_130322.csv'))\n",
      "nrsa_hab_cond_med = pandas.DataFrame(tmp,columns=['SITE_ID','UID','VISIT_NO','W1_HNOAG','W1H_WALL','W1H_PIPE','W1_HAG','W1_HALL',\n",
      "'REACHLEN','XFC_ALL','XWD_RAT','XCMGW','LRBS_BW5','XCDENBK','XG','XWIDTH','XFC_NAT','YEAR'])\n",
      "\n",
      "#OFFLINE VERSION\n",
      "\n",
      "#read in wsa site info\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/WSA_Data/WSAMarch2_2009/wsa_siteinfo_ts_final.csv'))\n",
      "wsa_siteinfo = pandas.DataFrame(tmp,columns=['SITE_ID','ECO3','ECOREPORT','COUNTY','ECOWSA3','ECOWSA9','EPAREGION','HUC8','SITENAME',\n",
      "                                             'STATE','STRAHLER','STRATUM','VISIT_NO','WGT_WSA','WSAREA','XELEV','XLAT_DD','XLON_DD','YEAR'])\n",
      "                                                      \n",
      "#read in watershed stressor data\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/WSA_Data/WSAMarch2_2009/watershedstressor.csv'))\n",
      "wsa_stressor = pandas.DataFrame(tmp,columns=['SITE_ID','VISIT_NO','YEAR','LANDAREA','PAGT','PFOR','POPDENS','PURB','PWETL',\n",
      "                                             'RDDENS'])\n",
      "\n",
      "#read in wsa benthic condition data\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/WSA_Data/WSAMarch2_2009/wsa_benmet300_ts_final.csv'))\n",
      "wsa_benthic = pandas.DataFrame(tmp,columns=['SITE_ID','VISIT_NO','YEAR','XWIDTH','STATE','SITENAME','MMI_WSABEST',\n",
      "'COMP_PT','RICH_PT','DIVS_PT','INTL_PT','HABT_PT','FEED_PT','EPT_PT','HPRIME','HPRI_PT'])\n",
      "\n",
      "#read in wsa chemistry data\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/WSA_Data/WSAMarch2_2009/waterchemistry.csv'))\n",
      "wsa_chem = pandas.DataFrame(tmp,columns=['SITE_ID','VISIT_NO','YEAR','NA','NTL','PTL','COND','CONDHO','ANC','DOC','TURB','TSS','NH4','SO4','K','MG','CL','CA'])\n",
      "\n",
      "#read in habitat data\n",
      "#phabbest is shortlist of habitat metrics- matches up nicely with nrsa\n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/WSA_Data/WSAMarch2_2009/phabbest.csv'))\n",
      "wsa_phabbest = pandas.DataFrame(tmp,columns=['SITE_ID','REACHLEN',\"VISIT_NO\",\"W1H_PIPE\",\"W1H_WALL\",\"W1_HAG\",\"W1_HALL\",\"W1_HNOAG\",\n",
      "\"XCDENBK\",\"XFC_ALL\",\"XFC_NAT\",\"XG\",'XWD_RAT',\"XWIDTH\",\"YEAR\",'XCMGW','LRBS_BW5'])\n",
      "  \n",
      "#read in rapid habitat assessment data                                             \n",
      "tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/WSA_Data/WSAMarch2_2009/rapidhabass.csv'))\n",
      "wsa_rapidhabass = pandas.DataFrame(tmp,columns=['SITE_ID','YEAR','VISIT_NO','BANK_STL','BANK_STR','CHAN_ALT','CHAN_FLS','CHAN_SIN',\n",
      "'EPIF_SUB','RIPA_VL','RIPA_VR'])   \n",
      "\n",
      "#read in habitat metric data  \n",
      "#tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/WSA_Data/WSAMarch2_2009/phabmet.csv'))                                 \n",
      "#wsa_phabmet = pandas.DataFrame(tmp,columns=['W1H_BLDG','W1H_CROP','W1H_LDFL','W1H_LOG','W1H_MINE','W1H_PARK','W1H_PIPE','W1H_PSTR','W1H_PVMT',\n",
      "#'W1H_ROAD','W1H_WALL','W1_HAG','W1_HALL','W1_HNOAG','XB_HAG','XB_HALL','XB_HNOAG','XC','XCB_HAG','XCB_HALL','XCB_HNAG','XWIDTH','XWXD'])          \n",
      "\n",
      "#read in riparian data                                             \n",
      "#tmp = pandas.DataFrame(read_csv('/Users/TScott/Google Drive/Watershed/Build/Inputs/WSA_Data/WSAMarch2_2009/riparian.csv'))\n",
      "#wsa_riparian = pandas.DataFrame(tmp,columns=['BLDG','BTRE','CANV','CROP','LDFL','LOG','MINACT','PARK',\n",
      "#'PIPE','PSTR','PVMT','ROAD','SITE_ID','UNDV','VISIT_NO','WALL','WOOD','YEAR'])   \n",
      "\n",
      "UID1 = [0] * wsa_siteinfo.shape[0]\n",
      "for i in xrange(0,wsa_siteinfo.shape[0]):\n",
      "    if wsa_siteinfo['VISIT_NO'][i] == 1:\n",
      "         UID1[i] = wsa_siteinfo['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID1[i] = wsa_siteinfo['SITE_ID'][i]+\"_2\"\n",
      "wsa_siteinfo.index = UID1 \n",
      "#wsa_siteinfo['UID'] = UID1\n",
      "\n",
      "UID1 = [0] * wsa_benthic.shape[0]\n",
      "for i in xrange(0,wsa_benthic.shape[0]):\n",
      "    if wsa_benthic['VISIT_NO'][i] == 1:\n",
      "         UID1[i] = wsa_benthic['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID1[i] = wsa_benthic['SITE_ID'][i]+\"_2\"\n",
      "wsa_benthic.index = UID1 \n",
      "#wsa_benthic['UID'] = UID1\n",
      "\n",
      "#UID1 = [0] * wsa_riparian.shape[0]\n",
      "#for i in xrange(0,wsa_riparian.shape[0]):\n",
      "#    if wsa_riparian['VISIT_NO'][i] == 1:\n",
      "#         UID1[i] = wsa_riparian['SITE_ID'][i]+\"_1\"\n",
      "#    else:\n",
      "#        UID1[i] = wsa_riparian['SITE_ID'][i]+\"_2\"\n",
      "#wsa_riparian.index = UID1 \n",
      "#wsa_riparian['UID'] = UID1\n",
      "\n",
      "UID_chem = [0] * wsa_chem.shape[0]\n",
      "for i in xrange(0,wsa_chem.shape[0]):\n",
      "    if wsa_chem['VISIT_NO'][i] == 1:\n",
      "        UID_chem[i] = wsa_chem['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID_chem[i] = wsa_chem['SITE_ID'][i]+\"_2\"\n",
      "wsa_chem.index = UID_chem\n",
      "#wsa_chem['UID'] = set(UID_chem)\n",
      "\n",
      "UID1 = [0] * wsa_phabbest.shape[0]\n",
      "for i in xrange(0,wsa_phabbest.shape[0]):\n",
      "    if wsa_phabbest['VISIT_NO'][i] == 1:\n",
      "         UID1[i] = wsa_phabbest['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID1[i] = wsa_phabbest['SITE_ID'][i]+\"_2\"\n",
      "wsa_phabbest.index = UID1 \n",
      "#wsa_phabbest['UID'] = UID1\n",
      "\n",
      "#UID1 = [0] * wsa_rapidhabass.shape[0]\n",
      "#for i in xrange(0,wsa_rapidhabass.shape[0]):\n",
      "#    if wsa_rapidhabass['VISIT_NO'][i] == 1:\n",
      "#         UID1[i] = wsa_rapidhabass['SITE_ID'][i]+\"_1\"\n",
      "#    else:\n",
      "#        UID1[i] = wsa_rapidhabass['SITE_ID'][i]+\"_2\"\n",
      "#wsa_rapidhabass.index = UID1 \n",
      "#wsa_rapidhabass['UID'] = UID1\n",
      "\n",
      "UID1 = [0] * wsa_stressor.shape[0]\n",
      "for i in xrange(0,wsa_stressor.shape[0]):\n",
      "    if wsa_stressor['VISIT_NO'][i] == 1:\n",
      "         UID1[i] = wsa_stressor['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID1[i] = wsa_stressor['SITE_ID'][i]+\"_2\"\n",
      "wsa_stressor.index = UID1 \n",
      "#wsa_stressor['UID'] = UID1\n",
      "\n",
      "#reindex nrsa data so that unique site x visit id is index\n",
      "nrsa_siteinfo.index = nrsa_siteinfo['UID']\n",
      "nrsa_benthic_cond.index = nrsa_benthic_cond['UID']\n",
      "nrsa_enterococci.index = nrsa_enterococci['UID']\n",
      "nrsa_fish_cond.index = nrsa_fish_cond['UID']\n",
      "#nrsa_hab_cond.index = nrsa_hab_cond['UID']\n",
      "nrsa_hab_cond_med.index = nrsa_hab_cond_med['UID']\n",
      "nrsa_peri_cond.index = nrsa_peri_cond['UID']\n",
      "nrsa_waterchem.index = nrsa_waterchem['UID']\n",
      "#nrsa_waterchem_cond.index = nrsa_waterchem_cond['UID']\n",
      "\n",
      "#MERGE NRSA DATA SETS, carry missing data in from right to left, merge columns and preserve unique columns\n",
      "temp = (nrsa_siteinfo.combine_first(nrsa_benthic_cond))\n",
      "temp1 = temp.combine_first(nrsa_enterococci)\n",
      "temp2 = temp1.combine_first(nrsa_fish_cond)\n",
      "#temp3 = temp2.combine_first(nrsa_hab_cond)\n",
      "temp4 = temp2.combine_first(nrsa_hab_cond_med)\n",
      "temp5 = temp4.combine_first(nrsa_peri_cond)\n",
      "temp6 = temp5.combine_first(nrsa_waterchem)\n",
      "#temp7 = temp6.combine_first(nrsa_waterchem_cond)\n",
      "nrsa_full = pandas.DataFrame(temp6)\n",
      "\n",
      "#MERGE WSA DATASETS\n",
      "temp = (wsa_siteinfo.combine_first(wsa_benthic))\n",
      "temp1 = temp.combine_first(wsa_chem)\n",
      "temp2 = temp1.combine_first(wsa_phabbest)\n",
      "#temp3 = temp2.combine_first(wsa_rapidhabass)\n",
      "temp4 = temp2.combine_first(wsa_stressor)\n",
      "wsa_full = temp4\n",
      "\n",
      "#rename variables to make them the same in wsa/nrsa\n",
      "wsa_test = wsa_full.rename(columns={'SITENAME':'LOC_NAME','EPAREGION':'EPA_REG','ECOWSA3':'FW_ECO3','ECOWSA9':'FW_ECO9','WGT_WSA':'POPWEIGHT','RICH_PT':'NTAX_PT',\n",
      "    'INTL_PT':'TOLR_PT','MMI_WSABEST':'MMI_BENT','NA':'SODIUM'})\n",
      "wsa_test['CON_ID'] = wsa_test['SITE_ID']\n",
      "nrsa_test = nrsa_full.rename(columns={'WGTNRSA09':'POPWEIGHT','STRAHLERORDER':'STRAHLER','NHDWAT_AREA_SQKM':'WSAREA','siteID05':'CON_ID'})\n",
      "nrsa_disag_benthicMMI = nrsa_full[['MMI_BENT_CPL','MMI_BENT_NAP','MMI_BENT_NPL','MMI_BENT_SAP','MMI_BENT_SPL','MMI_BENT_TPL','MMI_BENT_UMW','MMI_BENT_WMT','MMI_BENT_XER']]\n",
      "MMI_NRSABEST = nrsa_disag_benthicMMI.fillna(method='bfill',axis=1)\n",
      "nrsa_test['MMI_BENT'] = MMI_NRSABEST[[0]]\n",
      "\n",
      "#bfill missing values\n",
      "temp1 = nrsa_test\n",
      "temp2 = wsa_test\n",
      "tt1 = temp1.groupby(level=0)\n",
      "tt2 = temp2.groupby(level=0)\n",
      "f = lambda x: x.fillna(method='bfill')\n",
      "temp1trans = tt1.transform(f)\n",
      "temp2trans = tt2.transform(f)\n",
      "nrsa_bfill = temp1trans\n",
      "wsa_bfill = temp2trans\n",
      "\n",
      "#ffill missing values (this will make sure I get all 1st AND 2nd visits to wsa+nrsa sites)\n",
      "temp1 = nrsa_bfill\n",
      "temp2 = wsa_bfill\n",
      "tt1 = temp1.groupby(level=0)\n",
      "tt2 = temp2.groupby(level=0)\n",
      "f = lambda x: x.fillna(method='ffill')\n",
      "temp1trans = tt1.transform(f)\n",
      "temp2trans = tt2.transform(f)\n",
      "nrsa_ffill = temp1trans\n",
      "wsa_ffill = temp2trans\n",
      "\n",
      "#set multiindex survey>site>visit\n",
      "tuples_nrsa = zip(['nrsa']*nrsa_ffill.shape[0],nrsa_ffill['MASTER_SITEID'],nrsa_ffill['VISIT_NO'])\n",
      "tuples_wsa = zip(['wsa']*wsa_ffill.shape[0],wsa_ffill['SITE_ID'],wsa_ffill['VISIT_NO'])\n",
      "index_nrsa = pandas.MultiIndex.from_tuples(tuples_nrsa,names=['SURVEY','ID','VISIT'])\n",
      "index_wsa = pandas.MultiIndex.from_tuples(tuples_wsa,names=['SURVEY','ID','VISIT'])\n",
      "te = wsa_ffill\n",
      "te.index = index_wsa\n",
      "te1 = nrsa_ffill\n",
      "te1.index = index_nrsa\n",
      "nrsa_ready = te1\n",
      "wsa_ready = te\n",
      "\n",
      "#subset both nrsa and wsa datasets for just observations that occur in both\n",
      "wsa_indicator = nrsa_ready['WSA'].notnull()\n",
      "resample_df = nrsa_ready[wsa_indicator]\n",
      "resample_ids = pandas.Series(resample_df['MASTER_SITEID'])\n",
      "wsa_resampled = wsa_ready[wsa_ready['CON_ID'].isin(resample_ids)]\n",
      "\n",
      "#merge together wsa and nrsa\n",
      "merged_full = concat((resample_df,wsa_resampled),join='outer')\n",
      "\n",
      "merged_full.to_csv('//Users/TScott/Google Drive/duckabush/merged_watershed_data.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 118
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#read in created file, clean up and paste over common variables\n",
      "tmp = pandas.DataFrame(read_csv('//Users/TScott/Google Drive/duckabush/merged_watershed_data.csv'))\n",
      "w = pandas.DataFrame(tmp)\n",
      "wdata = w\n",
      "\n",
      "del wdata['CONDHO']\n",
      "del wdata['ENT_NEEAR_PCR_CCE_100ML']\n",
      "wdata['EPAREG']= wdata['EPA_REG'].str.replace('REGION__','')\n",
      "wdata['EPAREG']= wdata['EPAREG'].str.replace('REGION_','')\n",
      "del wdata['EPA_REG']\n",
      "temp1 = wdata['STRAHLER'].str.replace('th','')\n",
      "temp2 = temp1.str.replace('rd','')\n",
      "temp3 = temp2.str.replace('nd','')\n",
      "temp4 = temp3.str.replace('st','')\n",
      "wdata['STRAHLER'] = temp4\n",
      "del wdata['EPT_PT']\n",
      "del wdata['FISH_MMI_COND']\n",
      "del wdata['GREAT_RIVER']\n",
      "del wdata['DIVS_PT']\n",
      "del wdata['LMR_SITE']\n",
      "del wdata['MMI_BENT_CPL']\n",
      "del wdata['MMI_BENT_NAP']\n",
      "del wdata['MMI_BENT_NPL']\n",
      "del wdata['MMI_BENT_SAP']\n",
      "del wdata['MMI_BENT_SPL']\n",
      "del wdata['MMI_BENT_TPL']\n",
      "del wdata['MMI_BENT_UMW']\n",
      "del wdata['MMI_BENT_WMT']\n",
      "del wdata['MMI_BENT_XER']\n",
      "del wdata['MMI_FISH_WMTNS']\n",
      "del wdata['MMI_FISH_PLNLOW']\n",
      "del wdata['MMI_FISH_EHIGH']\n",
      "del wdata['MMI_PERI_WMTNS']\n",
      "del wdata['MMI_PERI_PLNLOW']\n",
      "del wdata['MMI_PERI_EHIGH']\n",
      "del wdata['NH4']\n",
      "del wdata['NRSA09']\n",
      "\n",
      "#DEBATABLY CONSTANT VARIABLES FOUND IN ONE DATASET BUT NOT THE OTHER\n",
      "#wdata['PAGT'] #wsa\n",
      "#wdata['PFOR'] #wsa\n",
      "#wdata['PURB'] #wsa\n",
      "#wdata['PWETL'] #wsa\n",
      "#wdata['RDDENS'] #wsa\n",
      "#wdata['POPDENS'] #wsa\n",
      "#wdata['XELEV'] #wsa\n",
      "\n",
      "#wdata['PAGT','PFOR','PURB','PWETL','RDDENS','POPDENS','XELEV','COUNTY','ECOREPORT']\n",
      "#wdata['MAJ_BAS_NM','FED_OWN','FSEASTWEST','MISS_SUB','UrbanCat']\n",
      "\n",
      "#CONSTANT VARIABLES FOUND IN ONE DATASET BUT NOT THE OTHER\n",
      "#wdata['MAJ_BAS_NM'] #NRSA\n",
      "#wdata['COUNTY'] #WSA\n",
      "#wdata['ECOREPORT'] #WSA\n",
      "#wdata['FED_OWN'] #nrsa\n",
      "#wdata['FSEASTWEST'] #nrsa\n",
      "#wdata['MISS_SUB'] #nrsa\n",
      "#wdata['UrbanCat'] #nrsa\n",
      "\n",
      "#fill from wsa to nrsa\n",
      "temp = wdata\n",
      "grpvar = temp['CON_ID']\n",
      "tt = temp.groupby(grpvar)\n",
      "f = lambda x: x.fillna(method='bfill')\n",
      "temp1trans = tt[['PAGT','PFOR','PURB','PWETL','RDDENS','POPDENS','XELEV','COUNTY','ECOREPORT']].transform(f)\n",
      "wdata[['PAGT','PFOR','PURB','PWETL','RDDENS','POPDENS','XELEV','COUNTY','ECOREPORT']] = temp1trans[['PAGT','PFOR','PURB','PWETL','RDDENS','POPDENS','XELEV','COUNTY','ECOREPORT']]\n",
      "#fill from nrsa to wsa\n",
      "temp1 = wdata\n",
      "tt1 = temp1.groupby(grpvar)\n",
      "f1 = lambda x: x.fillna(method='ffill')\n",
      "temp2trans = tt1[['MAJ_BAS_NM','FED_OWN','FSEASTWEST','MISS_SUB','UrbanCat']].transform(f1)\n",
      "wdata[['MAJ_BAS_NM','FED_OWN','FSEASTWEST','MISS_SUB','UrbanCat']] = temp2trans[['MAJ_BAS_NM','FED_OWN','FSEASTWEST','MISS_SUB','UrbanCat']]\n",
      "\n",
      "wdata.to_csv('//Users/TScott/Google Drive/duckabush/cleaned_and_copied_watershed_data.csv')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 105
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}