{
 "metadata": {
  "name": "",
  "signature": "sha256:7a88b3171460853661ca24ace8c18b7b70c55a67e2d6c1ec5065e50b0658476e"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "ONLINE VERSION: Read in site info data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#ipython --pylab\n",
      "import pandas\n",
      "from pandas import read_csv\n",
      "from urllib import urlopen\n",
      "import numpy as np\n",
      "from pandas import concat\n",
      "from pandas import merge\n",
      "\n",
      "#read in nrsa site info\n",
      "page = urlopen(\"http://water.epa.gov/type/rsl/monitoring/riverssurvey/upload/NRSA0809_Data_SiteInformation_130411.csv\")\n",
      "tmp = pandas.DataFrame(read_csv(page))\n",
      "nrsa_siteinfo = pandas.DataFrame(tmp,columns=['SITE_ID','MASTER_SITEID','UID','EPA_REG','FW_ECO3','FW_ECO9','GREAT_RIVER','HUC8','LMR_SITE','LOC_NAME',\n",
      "'MISS_SUB','NHDWAT_AREA_SQKM','STATE','STRAHLERORDER','VISIT_NO','WGTNRSA09','XLAT_DD','XLON_DD','YEAR'])\n",
      "\n",
      "#read in wsa site info\n",
      "page = urlopen(\"http://water.epa.gov/type/rsl/monitoring/streamsurvey/upload/wsa_siteinfo_ts_final.csv\")\n",
      "tmp = pandas.DataFrame(read_csv(page))\n",
      "wsa_siteinfo = pandas.DataFrame(tmp,columns=['SITE_ID','ECO3','ECOREPORT','COUNTY','ECOWSA3','ECOWSA9','EPAREGION','HUC8','SITENAME',\n",
      "                                             'STATE','STRAHLER','STRATUM','VISIT_NO','WGT_WSA','WSAREA','XELEV','XLAT_DD','XLON_DD','YEAR'])\n",
      "\n",
      "UID1 = [0] * wsa_siteinfo.shape[0]\n",
      "for i in xrange(0,wsa_siteinfo.shape[0]):\n",
      "    if wsa_siteinfo['VISIT_NO'][i] == 1:\n",
      "         UID1[i] = wsa_siteinfo['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID1[i] = wsa_siteinfo['SITE_ID'][i]+\"_2\"\n",
      "wsa_siteinfo.index = UID1 \n",
      "\n",
      "nrsa_uq = nrsa_siteinfo[nrsa_siteinfo.VISIT_NO==1]\n",
      "wsa_uq = wsa_siteinfo[wsa_siteinfo.VISIT_NO==1]\n",
      "\n",
      "origdat = pandas.DataFrame(read_csv('//Users/TScott/Google Drive/duckabush/management_data_v2.csv'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 50
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allinfo=wsa_uq.merge(nrsa_uq,left_on='SITE_ID',right_on='MASTER_SITEID',suffixes=('_wsa','_nrsa'),how='outer')\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nrsaonly=nrsa_siteinfo[nrsa_siteinfo.MASTER_SITEID.isin(origdat.CON_ID)==False]\n",
      "wsaonly=wsa_siteinfo[wsa_siteinfo.SITE_ID.isin(origdat.CON_ID)==False]\n",
      "#nrsaonly.to_csv('//Users/TScott/Google Drive/duckabush/not_in_wsa.csv')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "origdat['INBOTH'] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 72
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allinfo.SITE_ID_nrsa"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "0     NaN\n",
        "1     NaN\n",
        "2     NaN\n",
        "3     NaN\n",
        "4     NaN\n",
        "5     NaN\n",
        "6     NaN\n",
        "7     NaN\n",
        "8     NaN\n",
        "9     NaN\n",
        "10    NaN\n",
        "11    NaN\n",
        "12    NaN\n",
        "13    NaN\n",
        "14    NaN\n",
        "...\n",
        "3447    FW08WA044\n",
        "3448    FW08TX035\n",
        "3449    FW08TX042\n",
        "3450    FW08TX053\n",
        "3451    FW08TX043\n",
        "3452    FW08TX037\n",
        "3453    FW08CT003\n",
        "3454    FW08CT027\n",
        "3455    FW08CT008\n",
        "3456    FW08CT004\n",
        "3457    FW08TX057\n",
        "3458    FW08DE008\n",
        "3459    FW08DE015\n",
        "3460    FW08DE021\n",
        "3461    FW08IN013\n",
        "Name: SITE_ID_nrsa, Length: 3462, dtype: object"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "allinfo.SITE_ID_y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 79,
       "text": [
        "0     OWW04440-0595\n",
        "1     OWW04440-0595\n",
        "2     OWW04440-0163\n",
        "3     OWW04440-0163\n",
        "4     OWW04440-0115\n",
        "5     OWW04440-0291\n",
        "6               NaN\n",
        "7               NaN\n",
        "8               NaN\n",
        "9               NaN\n",
        "10              NaN\n",
        "11              NaN\n",
        "12              NaN\n",
        "13      WNVP99-0503\n",
        "14              NaN\n",
        "...\n",
        "3447    WWYP99-0719\n",
        "3448    WWYP99-0721\n",
        "3449    WWYP99-0722\n",
        "3450      WY1046744\n",
        "3451      WY1203762\n",
        "3452       WYO-0002\n",
        "3453       WYO-0032\n",
        "3454       WYO-0037\n",
        "3455       YNP-0019\n",
        "3456       YNP-0025\n",
        "3457       YNP-0039\n",
        "3458       YNP-0040\n",
        "3459       YNP-0073\n",
        "3460       YNP-0113\n",
        "3461       YNP-0117\n",
        "Name: SITE_ID_y, Length: 3462, dtype: object"
       ]
      }
     ],
     "prompt_number": 79
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "test = origdat.append(nrsaonly)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "0     2000\n",
        "1     2000\n",
        "2     2000\n",
        "3     2000\n",
        "4     2000\n",
        "5     2000\n",
        "6     2000\n",
        "7     2000\n",
        "8     2000\n",
        "9     2000\n",
        "10    2000\n",
        "11    2000\n",
        "12    2000\n",
        "13    2000\n",
        "14    2000\n",
        "...\n",
        "2101    2008\n",
        "2102    2008\n",
        "2104    2008\n",
        "2105    2008\n",
        "2106    2008\n",
        "2107    2009\n",
        "2108    2009\n",
        "2109    2009\n",
        "2110    2009\n",
        "2111    2009\n",
        "2112    2008\n",
        "2117    2008\n",
        "2118    2008\n",
        "2119    2008\n",
        "2120    2008\n",
        "Name: YEAR, Length: 2393, dtype: int64"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "\n",
      "#read in watershed stressor data\n",
      "page = urlopen(\"http://water.epa.gov/type/rsl/monitoring/streamsurvey/upload/watershedstressor.csv\")\n",
      "tmp = pandas.DataFrame(read_csv(page))\n",
      "wsa_stressor = pandas.DataFrame(tmp,columns=['SITE_ID','VISIT_NO','YEAR','LANDAREA','PAGT','PFOR','POPDENS','PURB','PWETL',\n",
      "                                             'RDDENS'])\n",
      "\n",
      "#read in wsa benthic condition data\n",
      "page = urlopen(\"http://water.epa.gov/type/rsl/monitoring/streamsurvey/upload/wsa_benmet300_ts_final.csv\")\n",
      "tmp = pandas.DataFrame(read_csv(page))\n",
      "wsa_benthic = pandas.DataFrame(tmp,columns=['SITE_ID','VISIT_NO','YEAR','XWIDTH','STATE','SITENAME','MMI_WSABEST',\n",
      "'COMP_PT','RICH_PT','DIVS_PT','INTL_PT','HABT_PT','FEED_PT','EPT_PT','HPRIME','HPRI_PT'])\n",
      "\n",
      "#read in wsa chemistry data\n",
      "page = urlopen(\"http://water.epa.gov/type/rsl/monitoring/streamsurvey/upload/waterchemistry.csv\")\n",
      "tmp = pandas.DataFrame(read_csv(page))\n",
      "wsa_chem = pandas.DataFrame(tmp,columns=['SITE_ID','VISIT_NO','YEAR','NTL','PTL','COND','CONDHO','ANC','DOC','TURB','TSS','NH4','SO4','K','MG','CL','CA'])\n",
      "\n",
      "#read in habitat data\n",
      "#phabbest is shortlist of habitat metrics- matches up nicely with nrsa\n",
      "page = urlopen(\"http://water.epa.gov/type/rsl/monitoring/streamsurvey/upload/phabbest.csv\")\n",
      "tmp = pandas.DataFrame(read_csv(page))\n",
      "wsa_phabbest = pandas.DataFrame(tmp,columns=['SITE_ID','REACHLEN',\"VISIT_NO\",\"W1H_PIPE\",\"W1H_WALL\",\"W1_HAG\",\"W1_HALL\",\"W1_HNOAG\",\n",
      "\"XCDENBK\",\"XFC_ALL\",\"XG\",'XWD_RAT',\"XWIDTH\",\"YEAR\",'XCMGW','XFC_NAT','LRBS_BW5','PCT_SAFN'])\n",
      "  \n",
      "#read in rapid habitat assessment data                                             \n",
      "page = urlopen(\"http://water.epa.gov/type/rsl/monitoring/streamsurvey/upload/rapidhabass.csv\")\n",
      "tmp = pandas.DataFrame(read_csv(page))\n",
      "wsa_rapidhabass = pandas.DataFrame(tmp,columns=['SITE_ID','YEAR','VISIT_NO','BANK_STL','BANK_STR','CHAN_ALT','CHAN_FLS','CHAN_SIN',\n",
      "'EPIF_SUB','RIPA_VL','RIPA_VR'])    \n",
      "\n",
      "#read in habitat metric data  \n",
      "#page = urlopen(\"http://water.epa.gov/type/rsl/monitoring/streamsurvey/upload/phabmet.csv\")\n",
      "#tmp = pandas.DataFrame(read_csv(page))                                   \n",
      "#wsa_phabmet = pandas.DataFrame(tmp,columns=['W1H_BLDG','W1H_CROP','W1H_LDFL','W1H_LOG','W1H_MINE','W1H_PARK','W1H_PIPE','W1H_PSTR','W1H_PVMT',\n",
      "#'W1H_ROAD','W1H_WALL','W1_HAG','W1_HALL','W1_HNOAG','XB_HAG','XB_HALL','XB_HNOAG','XC','XCB_HAG','XCB_HALL','XCB_HNAG','XWIDTH','XWXD'])          \n",
      "\n",
      "#read in riparian data                                             \n",
      "#page = urlopen(\"http://water.epa.gov/type/rsl/monitoring/streamsurvey/upload/riparian.csv\")\n",
      "#tmp = pandas.DataFrame(read_csv(page))\n",
      "#wsa_riparian = pandas.DataFrame(tmp,columns=['BLDG','BTRE','CANV','CROP','LDFL','LOG','MINACT','PARK',\n",
      "#'PIPE','PSTR','PVMT','ROAD','SITE_ID','UNDV','VISIT_NO','WALL','WOOD','YEAR'])   \n",
      "\n",
      "\n",
      "#wsa_siteinfo['UID'] = UID1\n",
      "\n",
      "UID1 = [0] * wsa_benthic.shape[0]\n",
      "for i in xrange(0,wsa_benthic.shape[0]):\n",
      "    if wsa_benthic['VISIT_NO'][i] == 1:\n",
      "         UID1[i] = wsa_benthic['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID1[i] = wsa_benthic['SITE_ID'][i]+\"_2\"\n",
      "wsa_benthic.index = UID1 \n",
      "#wsa_benthic['UID'] = UID1\n",
      "\n",
      "#UID1 = [0] * wsa_riparian.shape[0]\n",
      "#for i in xrange(0,wsa_riparian.shape[0]):\n",
      "#    if wsa_riparian['VISIT_NO'][i] == 1:\n",
      "#         UID1[i] = wsa_riparian['SITE_ID'][i]+\"_1\"\n",
      "#    else:\n",
      "#        UID1[i] = wsa_riparian['SITE_ID'][i]+\"_2\"\n",
      "#wsa_riparian.index = UID1 \n",
      "#wsa_riparian['UID'] = UID1\n",
      "\n",
      "UID_chem = [0] * wsa_chem.shape[0]\n",
      "for i in xrange(0,wsa_chem.shape[0]):\n",
      "    if wsa_chem['VISIT_NO'][i] == 1:\n",
      "        UID_chem[i] = wsa_chem['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID_chem[i] = wsa_chem['SITE_ID'][i]+\"_2\"\n",
      "wsa_chem.index = UID_chem\n",
      "#wsa_chem['UID'] = set(UID_chem)\n",
      "\n",
      "UID1 = [0] * wsa_phabbest.shape[0]\n",
      "for i in xrange(0,wsa_phabbest.shape[0]):\n",
      "    if wsa_phabbest['VISIT_NO'][i] == 1:\n",
      "         UID1[i] = wsa_phabbest['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID1[i] = wsa_phabbest['SITE_ID'][i]+\"_2\"\n",
      "wsa_phabbest.index = UID1 \n",
      "#wsa_phabbest['UID'] = UID1\n",
      "\n",
      "#UID1 = [0] * wsa_rapidhabass.shape[0]\n",
      "#for i in xrange(0,wsa_rapidhabass.shape[0]):\n",
      "#    if wsa_rapidhabass['VISIT_NO'][i] == 1:\n",
      "#         UID1[i] = wsa_rapidhabass['SITE_ID'][i]+\"_1\"\n",
      "#    else:\n",
      "#        UID1[i] = wsa_rapidhabass['SITE_ID'][i]+\"_2\"\n",
      "#wsa_rapidhabass.index = UID1 \n",
      "#wsa_rapidhabass['UID'] = UID1\n",
      "\n",
      "UID1 = [0] * wsa_stressor.shape[0]\n",
      "for i in xrange(0,wsa_stressor.shape[0]):\n",
      "    if wsa_stressor['VISIT_NO'][i] == 1:\n",
      "         UID1[i] = wsa_stressor['SITE_ID'][i]+\"_1\"\n",
      "    else:\n",
      "        UID1[i] = wsa_stressor['SITE_ID'][i]+\"_2\"\n",
      "wsa_stressor.index = UID1 \n",
      "#wsa_stressor['UID'] = UID1\n",
      "\n",
      "#reindex nrsa data so that unique site x visit id is index\n",
      "nrsa_siteinfo.index = nrsa_siteinfo['UID']\n",
      "nrsa_benthic_cond.index = nrsa_benthic_cond['UID']\n",
      "nrsa_enterococci.index = nrsa_enterococci['UID']\n",
      "nrsa_fish_cond.index = nrsa_fish_cond['UID']\n",
      "#nrsa_hab_cond.index = nrsa_hab_cond['UID']\n",
      "nrsa_hab_cond_med.index = nrsa_hab_cond_med['UID']\n",
      "nrsa_peri_cond.index = nrsa_peri_cond['UID']\n",
      "nrsa_waterchem.index = nrsa_waterchem['UID']\n",
      "#nrsa_waterchem_cond.index = nrsa_waterchem_cond['UID']\n",
      "\n",
      "#MERGE NRSA DATA SETS, carry missing data in from right to left, merge columns and preserve unique columns\n",
      "temp = (nrsa_siteinfo.combine_first(nrsa_benthic_cond))\n",
      "temp1 = temp.combine_first(nrsa_enterococci)\n",
      "temp2 = temp1.combine_first(nrsa_fish_cond)\n",
      "#temp3 = temp2.combine_first(nrsa_hab_cond)\n",
      "temp4 = temp2.combine_first(nrsa_hab_cond_med)\n",
      "temp5 = temp4.combine_first(nrsa_peri_cond)\n",
      "temp6 = temp5.combine_first(nrsa_waterchem)\n",
      "#temp7 = temp6.combine_first(nrsa_waterchem_cond)\n",
      "nrsa_full = pandas.DataFrame(temp6)\n",
      "\n",
      "#MERGE WSA DATASETS\n",
      "temp = (wsa_siteinfo.combine_first(wsa_benthic))\n",
      "temp1 = temp.combine_first(wsa_chem)\n",
      "temp2 = temp1.combine_first(wsa_phabbest)\n",
      "#temp3 = temp2.combine_first(wsa_rapidhabass)\n",
      "temp4 = temp2.combine_first(wsa_stressor)\n",
      "wsa_full = temp4\n",
      "\n",
      "#rename variables to make them the same in wsa/nrsa\n",
      "wsa_test = wsa_full.rename(columns={'SITENAME':'LOC_NAME','EPAREGION':'EPA_REG','ECOWSA3':'FW_ECO3','ECOWSA9':'FW_ECO9','WGT_WSA':'POPWEIGHT','RICH_PT':'NTAX_PT',\n",
      "    'INTL_PT':'TOLR_PT','MMI_WSABEST':'MMI_BENT'})\n",
      "wsa_test['CON_ID'] = wsa_test['SITE_ID']\n",
      "nrsa_test = nrsa_full.rename(columns={'WGTNRSA09':'POPWEIGHT','STRAHLERORDER':'STRAHLER','NHDWAT_AREA_SQKM':'WSAREA','siteID05':'CON_ID'})\n",
      "nrsa_disag_benthicMMI = nrsa_full[['MMI_BENT_CPL','MMI_BENT_NAP','MMI_BENT_NPL','MMI_BENT_SAP','MMI_BENT_SPL','MMI_BENT_TPL','MMI_BENT_UMW','MMI_BENT_WMT','MMI_BENT_XER']]\n",
      "MMI_NRSABEST = nrsa_disag_benthicMMI.fillna(method='bfill',axis=1)\n",
      "nrsa_test['MMI_BENT'] = MMI_NRSABEST[[0]]\n",
      "\n",
      "#bfill missing values\n",
      "temp1 = nrsa_test\n",
      "temp2 = wsa_test\n",
      "tt1 = temp1.groupby(level=0)\n",
      "tt2 = temp2.groupby(level=0)\n",
      "f = lambda x: x.fillna(method='bfill')\n",
      "temp1trans = tt1.transform(f)\n",
      "temp2trans = tt2.transform(f)\n",
      "nrsa_bfill = temp1trans\n",
      "wsa_bfill = temp2trans\n",
      "\n",
      "#ffill missing values (this will make sure I get all 1st AND 2nd visits to wsa+nrsa sites)\n",
      "temp1 = nrsa_bfill\n",
      "temp2 = wsa_bfill\n",
      "tt1 = temp1.groupby(level=0)\n",
      "tt2 = temp2.groupby(level=0)\n",
      "f = lambda x: x.fillna(method='ffill')\n",
      "temp1trans = tt1.transform(f)\n",
      "temp2trans = tt2.transform(f)\n",
      "nrsa_ffill = temp1trans\n",
      "wsa_ffill = temp2trans\n",
      "\n",
      "#set multiindex survey>site>visit\n",
      "tuples_nrsa = zip(['nrsa']*nrsa_ffill.shape[0],nrsa_ffill['MASTER_SITEID'],nrsa_ffill['VISIT_NO'])\n",
      "tuples_wsa = zip(['wsa']*wsa_ffill.shape[0],wsa_ffill['SITE_ID'],wsa_ffill['VISIT_NO'])\n",
      "index_nrsa = pandas.MultiIndex.from_tuples(tuples_nrsa,names=['SURVEY','ID','VISIT'])\n",
      "index_wsa = pandas.MultiIndex.from_tuples(tuples_wsa,names=['SURVEY','ID','VISIT'])\n",
      "te = wsa_ffill\n",
      "te.index = index_wsa\n",
      "te1 = nrsa_ffill\n",
      "te1.index = index_nrsa\n",
      "nrsa_ready = te1\n",
      "wsa_ready = te\n",
      "\n",
      "#subset both nrsa and wsa datasets for just observations that occur in both\n",
      "wsa_indicator = nrsa_ready['WSA'].notnull()\n",
      "resample_df = nrsa_ready[wsa_indicator]\n",
      "resample_ids = pandas.Series(resample_df['MASTER_SITEID'])\n",
      "wsa_resampled = wsa_ready[wsa_ready['CON_ID'].isin(resample_ids)]\n",
      "\n",
      "#merge together wsa and nrsa\n",
      "merged_full = concat((resample_df,wsa_resampled),join='outer')\n",
      "merged_full.to_csv('//Users/TScott/Google Drive/duckabush/merged_watershed_data.csv')\n",
      "\n",
      "#read in created file, clean up and paste over common variables\n",
      "tmp = pandas.DataFrame(read_csv('//Users/TScott/Google Drive/duckabush/merged_watershed_data.csv'))\n",
      "w = pandas.DataFrame(tmp)\n",
      "wdata = w\n",
      "\n",
      "del wdata['CONDHO']\n",
      "del wdata['ENT_NEEAR_PCR_CCE_100ML']\n",
      "wdata['EPAREG']= wdata['EPA_REG'].str.replace('REGION__','')\n",
      "del wdata['EPA_REG']\n",
      "temp1 = wdata['STRAHLER'].str.replace('th','')\n",
      "temp2 = temp1.str.replace('rd','')\n",
      "temp3 = temp2.str.replace('nd','')\n",
      "temp4 = temp3.str.replace('st','')\n",
      "wdata['STRAHLER'] = temp4\n",
      "del wdata['EPT_PT']\n",
      "del wdata['FISH_MMI_COND']\n",
      "del wdata['GREAT_RIVER']\n",
      "del wdata['DIVS_PT']\n",
      "del wdata['LMR_SITE']\n",
      "del wdata['MMI_BENT_CPL']\n",
      "del wdata['MMI_BENT_NAP']\n",
      "del wdata['MMI_BENT_NPL']\n",
      "del wdata['MMI_BENT_SAP']\n",
      "del wdata['MMI_BENT_SPL']\n",
      "del wdata['MMI_BENT_TPL']\n",
      "del wdata['MMI_BENT_UMW']\n",
      "del wdata['MMI_BENT_WMT']\n",
      "del wdata['MMI_BENT_XER']\n",
      "del wdata['MMI_FISH_WMTNS']\n",
      "del wdata['MMI_FISH_PLNLOW']\n",
      "del wdata['MMI_FISH_EHIGH']\n",
      "del wdata['MMI_PERI_WMTNS']\n",
      "del wdata['MMI_PERI_PLNLOW']\n",
      "del wdata['MMI_PERI_EHIGH']\n",
      "del wdata['NH4']\n",
      "del wdata['NRSA09']\n",
      "del wdata['SODIUM']\n",
      "\n",
      "#DEBATABLY CONSTANT VARIABLES FOUND IN ONE DATASET BUT NOT THE OTHER\n",
      "#wdata['PAGT'] #wsa\n",
      "#wdata['PFOR'] #wsa\n",
      "#wdata['PURB'] #wsa\n",
      "#wdata['PWETL'] #wsa\n",
      "#wdata['RDDENS'] #wsa\n",
      "#wdata['POPDENS'] #wsa\n",
      "#wdata['XELEV'] #wsa\n",
      "\n",
      "#wdata['PAGT','PFOR','PURB','PWETL','RDDENS','POPDENS','XELEV','COUNTY','ECOREPORT']\n",
      "#wdata['MAJ_BAS_NM','FED_OWN','FSEASTWEST','MISS_SUB','UrbanCat']\n",
      "\n",
      "#CONSTANT VARIABLES FOUND IN ONE DATASET BUT NOT THE OTHER\n",
      "#wdata['MAJ_BAS_NM'] #NRSA\n",
      "#wdata['COUNTY'] #WSA\n",
      "#wdata['ECOREPORT'] #WSA\n",
      "#wdata['FED_OWN'] #nrsa\n",
      "#wdata['FSEASTWEST'] #nrsa\n",
      "#wdata['MISS_SUB'] #nrsa\n",
      "#wdata['UrbanCat'] #nrsa\n",
      "\n",
      "#fill from wsa to nrsa\n",
      "temp = wdata\n",
      "grpvar = temp['CON_ID']\n",
      "tt = temp.groupby(grpvar)\n",
      "f = lambda x: x.fillna(method='bfill')\n",
      "temp1trans = tt[['PAGT','PFOR','PURB','PWETL','RDDENS','POPDENS','XELEV','COUNTY','ECOREPORT']].transform(f)\n",
      "wdata[['PAGT','PFOR','PURB','PWETL','RDDENS','POPDENS','XELEV','COUNTY','ECOREPORT']] = temp1trans[['PAGT','PFOR','PURB','PWETL','RDDENS','POPDENS','XELEV','COUNTY','ECOREPORT']]\n",
      "#fill from nrsa to wsa\n",
      "temp1 = wdata\n",
      "tt1 = temp1.groupby(grpvar)\n",
      "f1 = lambda x: x.fillna(method='ffill')\n",
      "temp2trans = tt1[['MAJ_BAS_NM','FED_OWN','FSEASTWEST','MISS_SUB','UrbanCat']].transform(f1)\n",
      "wdata[['MAJ_BAS_NM','FED_OWN','FSEASTWEST','MISS_SUB','UrbanCat']] = temp2trans[['MAJ_BAS_NM','FED_OWN','FSEASTWEST','MISS_SUB','UrbanCat']]\n",
      "\n",
      "wdata.to_csv('//Users/TScott/Google Drive/duckabush/cleaned_and_copied_watershed_data.csv')\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    }
   ],
   "metadata": {}
  }
 ]
}